{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greek-mechanism",
   "metadata": {},
   "source": [
    "## Usefuls sources of informations:\n",
    "\n",
    "* https://github.com/hbjornoy/deep-learning/blob/master/project2/helpers.py\n",
    "* https://github.com/Ertugrulmert/EPFL-Deep-Learning-Projects/blob/master/Project_2/framework.py\n",
    "* https://github.com/marieanselmet/DeepLearningEPFL_projects/tree/main/DL_framework_from_scratch\n",
    "\n",
    "La grande différence est que tout le monde définit module avec un argument, et non une liste * -> à voir si on doit changer pour faire comme les années précédentes ou s'il y a qqc de plus pratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "minimal-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1200e6490>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from torch import Tensor\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stable-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The father of all Modules\n",
    "class Module(object):\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-packing",
   "metadata": {},
   "source": [
    "## Activation\n",
    "\n",
    "À part ReLU et Tanh c'est pas précisé dans l'énoncé - là c'est juste pour le flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "devoted-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t = 0 \n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.t = input\n",
    "        return input.clamp(0)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        input = self.t\n",
    "        sign = input.sign().clamp(0)\n",
    "        return sign * gradwrtoutput\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "juvenile-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t = 0 \n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.t = input\n",
    "        \n",
    "        out = []\n",
    "        for x in input :\n",
    "            e = math.exp(-2 * x)\n",
    "            val = (1 - e) / (1 + e)\n",
    "            out.append(val)\n",
    "        return torch.FloatTensor(out)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        z = self.t\n",
    "        e = torch.exp(-2 * z)\n",
    "        d_tanh = 4 * e / (1 + e)**2\n",
    "        return d_tanh * gradwrtoutput\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "rapid-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t = 0 \n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.t = input\n",
    "        return input.mul(-1).exp().add(1).pow(-1)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        sig = self.t.mul(-1).exp().add(1).pow(-1)\n",
    "        return sig.mul(-1).add(1).mul(sig)\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e23a1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  1.,  3., 10.])\n",
      "tensor([-0.,  0.,  1.,  3., 10.])\n",
      "tensor([-1.0000,  0.0000,  0.7616,  0.9951,  1.0000])\n",
      "tensor([-8.2446e-08,  0.0000e+00,  4.1997e-01,  2.9598e-02,  8.2446e-08])\n",
      "tensor([4.5398e-05, 5.0000e-01, 7.3106e-01, 9.5257e-01, 9.9995e-01])\n",
      "tensor([4.5396e-05, 2.5000e-01, 1.9661e-01, 4.5177e-02, 4.5417e-05])\n"
     ]
    }
   ],
   "source": [
    "r = ReLU()\n",
    "th = Tanh()\n",
    "s = Sigmoid()\n",
    "\n",
    "t = torch.FloatTensor([-10, 0, 1, 3, 10])\n",
    "\n",
    "print(r.forward(t))\n",
    "print(r.backward(t))\n",
    "print(th.forward(t))\n",
    "print(th.backward(t))\n",
    "print(s.forward(t))\n",
    "print(s.backward(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyReLU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CReLU(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-romantic",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "public-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, input_size, output_size, mean=0, std=1):\n",
    "        super().__init__()\n",
    "        self.W = torch.empty(output_size, input_size).normal_(mean, std)\n",
    "        self.b = torch.empty(output_size).normal_(mean, std)\n",
    "        self.t = 0\n",
    "        self.dW = torch.zeros(output_size, input_size)\n",
    "        self.db = torch.zeros(output_size)\n",
    "    def forward(self, input):\n",
    "        self.t = input\n",
    "        return self.W.mv(input).add(self.b)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.dW.add_(gradwrtoutput.view(1, -1).t().mm(self.t.view(1, -1)))\n",
    "        self.db.add_(gradwrtoutput)\n",
    "        return self.W.t().mv(gradwrtoutput)\n",
    "        \n",
    "        \n",
    "    def param(self):\n",
    "        return [(self.W, self.dW), (self.b, self.db)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a16320dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3606, -4.9119,  2.2291, -3.7748, -4.0492,  1.6691, -1.0099,  1.2334,\n",
       "        -1.3293, -2.8563])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Linear(10, 10)\n",
    "t = torch.empty(10).fill_(1)\n",
    "l.forward(t)\n",
    "l.backward(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "49fa1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Module):\n",
    "    def __init__(self, p = 0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self, input):\n",
    "        for i in range(input.shape[0]):\n",
    "            if random.random() < self.p : \n",
    "                input[i] = 0 \n",
    "        return input\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        return gradwrtoutput\n",
    "        \n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fcf391b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Dropout(0.5)\n",
    "t = torch.empty(10).fill_(1)\n",
    "l.forward(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-account",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "\n",
    "Lui en input il prend une liste de modules et son fwd c'est de feed le fwd de chaque layer dans l'autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dirty-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Module):\n",
    "    def __init__(self, module_list):\n",
    "        super().__init__()\n",
    "        self.modules = module_list\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for module in self.modules :\n",
    "            x = module.forward(x)\n",
    "        return x \n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        x = gradwrtoutput\n",
    "        for module in self.modules :\n",
    "            x = module.backward(x)\n",
    "        return x\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8b904c19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-2109e52961a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-a4eb82e78e53>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradwrtoutput)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-3ad592a7aeb1>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradwrtoutput)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "s = Sequential([Linear(10,10), Linear(10,5), Linear(5,2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-representation",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "Seule lossMSE est demandé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMAE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss\n",
    "\n",
    "class LossBCE(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-beast",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Pas demandé mais fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, params, lr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mazel Tov si on y arrive\n",
    "class Adam():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-alfred",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print(\"EKIP\")\n",
    "    \n",
    "def test():\n",
    "    print(667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-confidence",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Faisons de la merde ici\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
